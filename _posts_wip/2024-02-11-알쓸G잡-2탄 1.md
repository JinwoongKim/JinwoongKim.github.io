---
title: "[알쓸G잡] 2탄 : GPU 메모리 구조와 쓰레드 구조"
categories: GPU
tags:
  - GPU
  - SM
  - Warp
published: false
---

# 1. Nvidia GPU 의 종류

<p align="center"> 

<img width="600" alt="image" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/99479a23-de1f-4aa4-ada7-d540489dd443">

<br>
<br>

<img width="600" alt="image" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/fe28790d-f431-41dd-a428-c0d3390f2fb3">

<br>
출처 : https://en.wikipedia.org/wiki/CUDA

</p>


## 용어 설명
- Compute capability (이하 CC): 말그대로 연산 능력이다. GPU 코어가 동시에 몇개의 쓰레드를 수행 할 수 있는지 등이 다르다.
- Micro-architecture : GPU의 근간이 되는 아키텍쳐 이름이다. 같은 아키텍쳐에서 여러 CC 가 있을 수 있다.
	- Ampere 아키텍쳐에서 A100은 CC가 8.0이고 A40은 8.6이다. 
	- 일반적으로 CC가 높으면 지원하는 기능들이 더 많다.

<p align="center">

<img width="578" alt="Pasted image 20240213214647" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/30a28b75-a900-4ecd-9a2c-4e4fdc157d73">

</p>
- GPUs : 코드 네임. 뒤에 나오는 GeForce, Quadro, Tesla 등의 기반이 되는 GPU 구조이다.
	- 예를 들어 똑같은 에스프레소샷에 따듯한 물타면 뜨아, 얼음타면 아아 되듯이, 같은 GPU 아키텍쳐를 이용해서 그래픽 관련 모듈 설치하고 RT 코어 달고 하면 게임 용 GeFore, 그래픽 포트 없애고 Tensor 코어를 달고, DRAM 더욱 집적해서서 과학연산 용으로 만들면 Tesla, 이런 식으로 생각하면 된다.
	- Quadro는 GeForce와 Tesla를 섞은 느낌이다. 화면 출력도 되고 메모리 집적도도 어느 정도 높다. 보통 (24시간 실험하는) 대학원생이나 개인 장비를 소유하는 연구자들이 출력 및 관리가 용이해 많이 쓴다. Tesla 는 서버렉에 설치하는 형태가 일반적이고 Quadro는 데스크탑 형태이기 때문이다. 
	- Jetson 라인은 자율주행 자동차에 들어가는 라인이다.
- 본 글에서는 Tesla, IDC 용 GPU 를 타겟으로 서술 하겠다.

# 2.  GPU Architecture
## CPU vs. GPU 구조 비교

<p align="center">

<img width="600" alt="Pasted image 20240206111150" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/18535d38-1afd-4b01-a6b4-4c6642475c2d">

<br>
출처 : https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html

</p>

- 위는 CPU와 GPU의 구조를 비교한 그림이다. 개론적인 그림이지만 얼핏 봐도 CPU 대비 GPU 코어의 갯수가 압도적으로 많다.
- GPU 는 CPU 대비 코어 각각의 성능은 낮다. 코어당 컨트롤러의 크기도 작고 L1 cache의 크기도 작아서 recursion 같은 연산에도 적합하지 않다.
	- 초기 GPU는 모니터 화면에 값을 연산해서 뿌려주는 용도 였기 때문에 이러한 구조를 가지게 되었다.
	- 하지만 이러한 구조 덕분에 CPU 보다 병렬처리에 적합하다. 
- 이러한 GPU 코어의 병렬성을 활용하기 위해서 GPU의 메모리는 대역폭이 매우 큰 것이 특징이다.

## GPU 내부 구조
- 아래 그림은 H100 백서에 나오는 GH100(H100, H200의 베이스) 의 구조이다.
- 가운데에 GPU 칩셋들(이하 SM)과 L2 캐시가 있으며, 주위를 메모리와 PCIe, NVLink 컨트롤러가 둘러싸고 있다.
- 여기서 우리가 주목해야 할 것은 SM이다. 하나의 GPU는 여러개의 SM으로 구성되어 있으며 하나의 SM 안에는 여러 종류의 GPU 코어와 메모리로 구성되어있다. 
- H100 SXM5(NVSwitch) 는 132 개의 SM 을 갖고 있으며, PCIe 버전은 114개의 SM 을 갖고 있다.
	- 참고로 A100의 SM의 갯수는 108개 이다.

<p align="center">

<img width="900" alt="Pasted image 20240206110349" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/0f49f423-d48d-4869-810a-6520bdc179f0">
<br>
출처 : nvidia-h100-tensor-core-hopper-whitepaper.pdf
</p>

## Streaming Multiprocessor (SM) 구조

- SM은 또 여러개의 SP로 구성이 되어있는데, 이는 아키텍쳐마다, GPU 모델마다 다르다.
- H100의 경우 하나의 SM이 4개의 SP로 구성되어 있다.
- SM내 SP들은 L1 캐쉬와 Shared Memory를 공유한다.
- 같은 SM안에 있지만 다른 SP 안에 있는 코어들끼리는 데이터를 교환하기 위해 이 공유 메모리를 사용한다.
- 일반적으로 On-chip 메모리라고 하면 SM 안에 있는 Shared Memory를 뜻하고 Off-ship 메모리라고 하면 밖에 있는 (Global/Device) Memory 를 뜻한다.
	- FlashAttention 및 여러 GPU-aware 한 논문들의 주요 가속화 방법 중 하나가 연산 수를 늘리더라도 off-chip 메모리 접근을 최소화 하는 것이다.
	- On-chip과 off-chip 메모리의 접근속도는 약 7~8배 정도가 차이 난다. 물론 대역폭은 off-chip이 더 높다.

<p align="center"> <img width="600" alt="Pasted image 20240206110314" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/85afb4c6-9e14-45cb-a204-4a8fc250bded">
<br>
출처 : nvidia-h100-tensor-core-hopper-whitepaper.pdf
</p>

### Streaming Processor (SP) 구조

<p align="center"><img width="400" alt="image" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/58ea1400-ab3b-487a-b139-7b8a813d284c">
<br>
출처 : nvidia-h100-tensor-core-hopper-whitepaper.pdf
</p>

- 각각의 SP에는 여러 종류의 코어와 컨트롤 유닛이 있다.
	- Tesla 모델등 딥러닝 학습을 위한 모델에는 텐서코어가 내장되어 있다는 것이다.
	- 텐서코어는 행렬곱을 가속화한 장치로써 일반적으로 GPU 코어는 1 clock 동안 하나의 부동소수점 연산을 하는데 반해, 텐서코어는 4x4 행렬곱을 수행한다.
		- 이때 입력은 FP16, 출력은 FP32 이라 mixed precision 이라고 부르기도 한다.

<p align="center"> <img width="900" alt="Pasted image 20240214124645" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/b96e86ff-e94a-46fa-888d-052cc5fdfc76"> 
<br>
GPU 프로파일화면 캡쳐. 텐서코어 사용률을 확인 할 수 있다.
</p>


# 3. GPU Thread Hierarchy

- CPU 는 쓰레드가 1차원인데 반해, GPU 여러 계층 및 차원으로 이루어져 있다.
- Grid with Clusters → Thread Block Cluster → Thread Block →  Warp →  Thread
<p align="center">

<img width="700" alt="Pasted image 20240206121933" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/43c3d5a3-2157-41cd-aa57-fdfb1e731dab">

<br>

출처 : https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html

</p>
- CUDA 프로그래밍을 하려고 한다면 다 알아야 되지만, 너무 복잡하다. 우리는 두 가지만 생각하자. '블럭', 그리고 '쓰레드'
	- 예를 들어 블럭 2개, 쓰레드 3개를 생성한다고 치면, GPU 블럭2개가 만들어지고 각각 블럭 안에 쓰레드가 3개씩 생성되는 식이다.
- 각각의 블럭은 동시에 하나의 SM에서만 수행 된다.
- 즉, 아래 그림처럼 블럭을 총 8개를 생성하면, SM 이 두 개인 GPU 는 왼쪽과 같이, 4개인 GPU는 오른쪽 같이 실행 된다.
	- 물론 SM의 상태에 따라 블럭이 다이나믹하게 할당 됨.
		- H100의 경우 하나의 SM이 32개의 블럭을 처리 할 수 있다. 참고로 A40, A100은 각각 16개, 32개이다.

<p align="center">

<img width="350" alt="Pasted image 20240206121605" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/b99bf320-6c54-4920-a730-338bc9a3d509">

<br>
출처 : https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html

</p>

- 쿠다 코드 보여줄지 말지 고민 필요

```c

#include <stdio.h>


__global__ void add(int *c, int* a, int* b, int num){
  int i = blockDim.x * blockIdx.x + threadIdx.x;
  i range (0 ~ *8*32-1))
  *c = *a + *b;
  i ,...
   if blockIdx.x % 2 == 0 {
   / lasdflksjfjdsaklfsd
   }
}



int main() {
  // cpu side

  // setting in host side
  int h_a = 4;
  int h_b = 7;
  int h_c;

  // setting in device side
  int* d_a;
  cudaMalloc(&d_a, sizeof(int));
  int* d_b;
  cudaMalloc(&d_b, sizeof(int));
  int* d_c;
  cudaMalloc(&d_c, sizeof(int));


  // cpu -> gpu
  cudaMemcpy(d_a, &h_a, sizeof(int), cudaMemcpyHostToDevice);
  cudaMemcpy(d_b, &h_b, sizeof(int), cudaMemcpyHostToDevice);

  add<<<8,32>>>(d_c, d_a, d_b, 1);

  cudaMemcpy(&h_c, d_c, sizeof(int), cudaMemcpyDeviceToHost);

  printf("%d\n",h_c);
}
```

# 4. GPU Trick or Tweak

- memory coalescing https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses
	- global memory 는 .. 무조건 256? align?
	- > Any address of a variable residing in global memory or returned by one of the memory allocation routines from the driver or runtime API is always aligned to at least 256 bytes.
	- soa, aos again
- unrolling
	- 많은 수의 코어가 놀지 않게 계속 데이터를 퍼주는게 GPU 병렬화의 핵심
	  - SIMT
		  - WARP (전우조)
			- 병렬화 최적화, 코어의 성능이 안 좋아서 최소 32개 묶음
				- 전우조라는 언급을 했듯이, if else 문이 있다고 했을때, 하나의 쓰레드라도 하나의 분기문에 해당되면 둘 다 들러야 함
				- 그래서, 분기문 안타게 코딩하는게 국룰
		- warp divergence
	- ILP

-  다이나믹 페러렐리즘
		- 커널 안에서 또 커널, 커널 런칭 오버헤드 감소

- Kernel fusion

- 유니파이드 메모리

- 스트림

- 싱크로나이제이션


# 5. Data movement
CPU - GPU
![[blog/images/스크린샷 2024-02-06 11.38.35.png]]
- 대충 recall느낌으로 그림 그려넣고
- 머 할때마다 최악은 사장한테 가는 거다
- DRI 가져야 한다
- 그래서 on-chip에서 해결하는겢 ㅔ일 좋다.
- FlashAttention의 핵심도 결국 off-chip memory (HBM) 적게 엑세스 하는 것이다.

GPU - GPU
![[blog/images/Pasted image 20240206134829.png]]
Server - Server

# 6. Limitations

- 호환성
	- CPU 와의 호환성
	- GPU 와의 호환성

 

#### 챕터1
- 21p
- 프레임 버퍼 용어 유래
- GPU 종류
	- GeForce, Quadro, Tesla
- 왜 병렬 특화? → 덜 정교하더라도 한 번에 뙇, 빠르게 계속 ...
	- for 0.001 1000번 더하면 다르고 막..
- 39p
- many core system, memory 는 작다
	- 구조 살짝 설명..
- 41
- GPU - CPU 간 데이터 전송
	- 결국 젤 느린 놈으로 속도 맞춰짐
- 각종 용어 설명
	- Global memory, device memory, on-chip, off-chip, PCI등등
- 43
- SoA, AoS


![[../images/AOS-vs-SOA-data-access-patterns 2.png]]
![[../images/AOS-vs-SOA-data-access-patterns 1.png]]
![[AOS-vs-SOA-data-access-patterns.png]]

- 47
- DMA
- GPU Direct
- 49
- SIMD, SMIT

#### 챕터2
-  69
	- GPU 아키텍쳐 설명
		- DRAM → shared mem, SM, 다양한 INT, Fp32, FP64, TENSOR core 등
- 70
	- 과학기술연산 64비트
	- 딥러닝? 필요 없음;
- 75
	- SIMD, SIMT
		- ILP
		- unrolling technic

#### 챕터3
- 120
	- 높은 연산 성능으로 용도 확장
		- 범위가 무척 넓음
		- 물리엔진, 시뮬레이션, PIConGPU 등..
- 123
	- 초기에는 CPU랑 GPU 연산이 달랏음
	- V100이랑 A100도 달랏음
- 129
	- 많은 수의 코어가 놀지 않게 계속 데이터를 퍼주는게 GPU 병렬화의 핵심
- 133
	- IBM POWER8, NVLink ㅎㄷ;
- 134
	- 우주방사선 CMOS;;

#### 챕터4
- 145
	- SIMT, WARP
		- 코어의 성능이 안 좋아서 최소 32개 묶음
			- 전우조
		- 하지만 volta 부턴 이것도 아니긴 함;; 그런데 성능을 위해서 32개로 묶음
- 147
	- 전우조라는 언급을 했듯이, if else 문이 있다고 했을때, 하나의 쓰레드라도 하나의 분기문에 해당되면 둘 다 들러야 함
	- 그래서, 분기문 안타게 코딩하는게 국룰
	- unrolling
	- warp divergence
- 149
	- GPU architecture H100
	- 물리적 구조
		- DRAM - SM (Shared Memory) , Cores (종류가 많다), Register
	- 논리적 구조
- 152
	- 간단한 쿠다 코드 보여주자
	- 다이나믹 페러렐리즘
		- 커널 안에서 또 커널, 커널 런칭 오버헤드 감소
- 154
	- 그리드와 쓰레드 블록 관리
	- 블록 생성 → SM에 할당
		- SM 은 한번에 하나의 블록 실행
- 161
	- memory coalescing https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses
		- global memory 는 .. 무조건 256? align?
		- > Any address of a variable residing in global memory or returned by one of the memory allocation routines from the driver or runtime API is always aligned to at least 256 bytes.
		- soa, aos again
- 163
	- L1, L2, shared 메모리 비교
	- oh chip, off chip 메모리
- 179
	- 유니파이드 메모리



[![CUDA Stream - Lei Mao's Log Book](https://leimao.github.io/images/blog/2020-02-02-CUDA-Stream/cuda-stream.png)![CUDA Stream - Lei Mao's Log Book](data:image/png;base64,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)](https://www.google.com/url?sa=i&url=https%3A%2F%2Fleimao.github.io%2Fblog%2FCUDA-Stream%2F&psig=AOvVaw0hRHeLr67AiZNHD31XvT95&ust=1706688484710000&source=images&cd=vfe&opi=89978449&ved=0CBIQjRxqFwoTCODgh5nUhIQDFQAAAAAdAAAAABAD)

#### 챕터 5
- 208
	- 간단한 cuda 코드
- 214
	- 스트림
- 218
	- syncronization
- 237
	- warp divergence

#### 챕터6
- 266
	- HBM
- 272
	- P2P
- 273
	- GPU Direct
- 275
	- NVLINK