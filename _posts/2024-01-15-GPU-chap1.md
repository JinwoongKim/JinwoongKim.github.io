---
title: "[파이썬] vi 편집기 이용시 black 으로 자동 포멧팅 하기"
categories: python
tags:
  - Python
  - black
  - vi
published: false
---
- 21p
- 프레임 버퍼 용어 유래
- GPU 종류
	- GeForce, Quadro, Tesla
- 왜 병렬 특화? → 덜 정교하더라도 한 번에 뙇, 빠르게 계속 ...
	- for 0.001 1000번 더하면 다르고 막..
- 39p
- many core system, memory 는 작다
	- 구조 살짝 설명..
- 41
- GPU - CPU 간 데이터 전송
	- 결국 젤 느린 놈으로 속도 맞춰짐
- 각종 용어 설명
	- Global memory, device memory, on-chip, off-chip, PCI등등
- 43
- SoA, AoS
<img src="/images/지금만나러갑니다.jpg" />
<img src="/images/AOS-vs-SOA-data-access-patterns 2.png" />
![[../images/AOS-vs-SOA-data-access-patterns 2.png]]
![[../images/AOS-vs-SOA-data-access-patterns 1.png]]
![[AOS-vs-SOA-data-access-patterns.png]]

- 47
- DMA
- GPU Direct
- 49
- SIMD, SMIT

챕터2
-  69
	- GPU 아키텍쳐 설명
		- DRAM → shared mem, SM, 다양한 INT, Fp32, FP64, TENSOR core 등
- 70
	- 과학기술연산 64비트
	- 딥러닝? 필요 없음;
- 75
	- SIMD, SIMT
		- ILP
		- unrolling technic

챕터3
- 120
	- 높은 연산 성능으로 용도 확장
		- 범위가 무척 넓음
		- 물리엔진, 시뮬레이션, PIConGPU 등..
- 123
	- 초기에는 CPU랑 GPU 연산이 달랏음
	- V100이랑 A100도 달랏음
- 129
	- 많은 수의 코어가 놀지 않게 계속 데이터를 퍼주는게 GPU 병렬화의 핵심
- 133
	- IBM POWER8, NVLink ㅎㄷ;
- 134
	- 우주방사선 CMOS;;

챕터4
- 145
	- SIMT, WARP
		- 코어의 성능이 안 좋아서 최소 32개 묶음
			- 전우조
		- 하지만 volta 부턴 이것도 아니긴 함;; 그런데 성능을 위해서 32개로 묶음
- 147
	- 전우조라는 언급을 했듯이, if else 문이 있다고 했을때, 하나의 쓰레드라도 하나의 분기문에 해당되면 둘 다 들러야 함
	- 그래서, 분기문 안타게 코딩하는게 국룰
	- unrolling
	- warp divergence
- 149
	- GPU architecture H100
	- 물리적 구조
		- DRAM - SM (Shared Memory) , Cores (종류가 많다), Register
	- 논리적 구조
- 152
	- 간단한 쿠다 코드 보여주자
	- 다이나믹 페러렐리즘
		- 커널 안에서 또 커널, 커널 런칭 오버헤드 감소
- 154
	- 그리드와 쓰레드 블록 관리
	- 블록 생성 → SM에 할당
		- SM 은 한번에 하나의 블록 실행
- 161
	- memory coalescing https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses
		- global memory 는 .. 무조건 256? align?
		- > Any address of a variable residing in global memory or returned by one of the memory allocation routines from the driver or runtime API is always aligned to at least 256 bytes.
		- soa, aos again
- 163
	- L1, L2, shared 메모리 비교
	- oh chip, off chip 메모리
- 179
	- 유니파이드 메모리