---
title: "[알쓸G잡] 2탄 : GPU 메모리 구조와 쓰레드 구조"
categories: GPU
tags:
  - GPU
  - SM
  - Warp
published: true
---

# 1. Nvidia GPU 의 종류

<p align="center"> 

<img width="600" alt="image" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/99479a23-de1f-4aa4-ada7-d540489dd443">

<br>
<br>

<img width="600" alt="image" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/fe28790d-f431-41dd-a428-c0d3390f2fb3">

<br>
출처 : https://en.wikipedia.org/wiki/CUDA

</p>


## 용어 설명
- Compute capability (이하 CC): 말그대로 연산 능력이다. GPU 코어가 동시에 몇개의 쓰레드를 수행 할 수 있는지 등이 다르다.
- Micro-architecture : GPU의 근간이 되는 아키텍쳐 이름이다. 같은 아키텍쳐에서 여러 CC 가 있을 수 있다.
	- Ampere 아키텍쳐에서 A100은 CC가 8.0이고 A40은 8.6이다. 
	- 일반적으로 CC가 높으면 지원하는 기능들이 더 많다.

<p align="center">

<img width="700" alt="Pasted image 20240213214647" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/30a28b75-a900-4ecd-9a2c-4e4fdc157d73">

</p>
- GPUs : 코드 네임. 뒤에 나오는 GeForce, Quadro, Tesla 등의 기반이 되는 GPU 구조이다.
	- 예를 들어 똑같은 에스프레소샷에 따듯한 물타면 뜨아, 얼음타면 아아 되듯이, 같은 GPU 아키텍쳐를 이용해서 그래픽 관련 모듈 설치하고 RT 코어 달고 하면 게임 용 GeFore, 그래픽 포트 없애고 Tensor 코어를 달고, DRAM 더욱 집적해서서 과학연산 용으로 만들면 Tesla, 이런 식으로 생각하면 된다.
	- Quadro는 GeForce와 Tesla를 섞은 느낌이다. 화면 출력도 되고 메모리 집적도도 어느 정도 높다. 보통 (24시간 실험하는) 대학원생이나 개인 장비를 소유하는 연구자들이 출력 및 관리가 용이해 많이 쓴다. Tesla 는 서버렉에 설치하는 형태가 일반적이고 Quadro는 데스크탑 형태이기 때문이다. 
	- Jetson 라인은 자율주행 자동차에 들어가는 라인이다.
- 본 글에서는 Tesla, IDC 용 GPU 를 타겟으로 서술 하겠다.

# 2.  GPU Architecture
## CPU vs. GPU 구조 비교

<p align="center">

<img width="600" alt="Pasted image 20240206111150" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/18535d38-1afd-4b01-a6b4-4c6642475c2d">

<br>
출처 : https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html

</p>

- 위는 CPU와 GPU의 구조를 비교한 그림이다. 개론적인 그림이지만 얼핏 봐도 CPU 대비 GPU 코어의 갯수가 압도적으로 많다.
- GPU 는 CPU 대비 코어 각각의 성능은 낮다. 코어당 컨트롤러의 크기도 작고 L1 cache의 크기도 작아서 recursion 같은 연산에도 적합하지 않다.
	- 초기 GPU는 모니터 화면에 값을 연산해서 뿌려주는 용도 였기 때문에 이러한 구조를 가지게 되었다.
	- 하지만 이러한 구조 덕분에 CPU 보다 병렬처리에 적합하다. 
- 이러한 GPU 코어의 병렬성을 활용하기 위해서 GPU의 메모리는 대역폭이 매우 큰 것이 특징이다.

## GPU 내부 구조
- 아래 그림은 H100 백서에 나오는 GH100(H100, H200의 베이스) 의 구조이다.
- 가운데에 GPU 칩셋들(이하 SM)과 L2 캐시가 있으며, 주위를 메모리와 PCIe, NVLink 컨트롤러가 둘러싸고 있다.
- 여기서 우리가 주목해야 할 것은 SM이다. 하나의 GPU는 여러개의 SM으로 구성되어 있으며 하나의 SM 안에는 여러 종류의 GPU 코어와 메모리로 구성되어있다. 
- H100 SXM5(NVSwitch) 는 132 개의 SM 을 갖고 있으며, PCIe 버전은 114개의 SM 을 갖고 있다.
	- 참고로 A100의 SM의 갯수는 108개 이다.

<p align="center">

<img width="900" alt="Pasted image 20240206110349" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/0f49f423-d48d-4869-810a-6520bdc179f0">
<br>
출처 : nvidia-h100-tensor-core-hopper-whitepaper.pdf
</p>

## Streaming Multiprocessor (SM) 구조

- SM은 또 여러개의 SP로 구성이 되어있는데, 이는 아키텍쳐마다, GPU 모델마다 다르다.
- H100의 경우 하나의 SM이 4개의 SP로 구성되어 있다.
- SM내 SP들은 L1 캐쉬와 Shared Memory를 공유한다.
- 같은 SM안에 있지만 다른 SP 안에 있는 코어들끼리는 데이터를 교환하기 위해 이 공유 메모리를 사용한다.
- 일반적으로 On-chip 메모리라고 하면 SM 안에 있는 Shared Memory를 뜻하고 Off-ship 메모리라고 하면 밖에 있는 (Global/Device) Memory 를 뜻한다.
	- FlashAttention 및 여러 GPU-aware 한 논문들의 주요 가속화 방법 중 하나가 연산 수를 늘리더라도 off-chip 메모리 접근을 최소화 하는 것이다.
	- On-chip과 off-chip 메모리의 접근속도는 약 7~8배 정도가 차이 난다. 물론 대역폭은 off-chip이 더 높다.

<p align="center"> <img width="600" alt="Pasted image 20240206110314" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/85afb4c6-9e14-45cb-a204-4a8fc250bded">
<br>
출처 : nvidia-h100-tensor-core-hopper-whitepaper.pdf
</p>

### Streaming Processor (SP) 구조

<p align="center"><img width="400" alt="image" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/58ea1400-ab3b-487a-b139-7b8a813d284c">
<br>
출처 : nvidia-h100-tensor-core-hopper-whitepaper.pdf
</p>

- 각각의 SP에는 여러 종류의 코어와 컨트롤 유닛이 있다.
	- Tesla 모델등 딥러닝 학습을 위한 모델에는 텐서코어가 내장되어 있다는 것이다.
	- 텐서코어는 행렬곱을 가속화한 장치로써 일반적으로 GPU 코어는 1 clock 동안 하나의 부동소수점 연산을 하는데 반해, 텐서코어는 4x4 행렬곱을 수행한다.
		- 이때 입력은 FP16, 출력은 FP32 이라 mixed precision 이라고 부르기도 한다.

<p align="center"> <img width="900" alt="Pasted image 20240214124645" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/b96e86ff-e94a-46fa-888d-052cc5fdfc76"> 
<br>
GPU 프로파일화면 캡쳐. 텐서코어 사용률을 확인 할 수 있다.
</p>

- FlashAttenion을 포함한 대부분의 딥러닝 GPU-aware 테크닉에서는 대역폭은 높지만 접근 속도가 느린 Global memory 접근을 최소화하고, Shared memory를 최대한 활용하는 식으로 성능 향상을 꾀한다.
- 그렇게 하기 위해서는 알고리즘 적으로 조치가 필요한데, 가장 흔한 것이 DnC의 타일링 이다. 이때 타일의 사이즈를 SBM 사이즈로 맞추는 식으로. → FlashAttention
	- 그런데 단순히 타일링을 해선 안되고 SN (shared-nothing) 구조를 가져야 한다. 이 때 알고리즘 적으로 여러가지 시도가 생기는데, 일반적으로 time complexity가 증가하게 된다.
	- 하지만 GPU는 computation 이 memeory acecss 보다 싸기 때문에 이러한 접근법이 효과적이다.

# 3. GPU Thread Hierarchy

- CPU 는 쓰레드가 1차원인데 반해, GPU 여러 계층 및 차원으로 이루어져 있다.
- Grid with Clusters → Thread Block Cluster → Thread Block →  Warp →  Thread
<p align="center">

<img width="700" alt="Pasted image 20240206121933" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/43c3d5a3-2157-41cd-aa57-fdfb1e731dab">

<br>

출처 : https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html

</p>
- CUDA 프로그래밍을 하려고 한다면 다 알아야 되지만, 너무 복잡하다. 우리는 두 가지만 생각하자. '블럭', 그리고 '쓰레드'
	- 예를 들어 블럭 2개, 쓰레드 3개를 생성한다고 치면, GPU 블럭2개가 만들어지고 각각 블럭 안에 쓰레드가 3개씩 생성되는 식이다.
- 각각의 블럭은 동시에 하나의 SM에서만 수행 된다.
- 즉, 아래 그림처럼 블럭을 총 8개를 생성하면, SM 이 두 개인 GPU 는 왼쪽과 같이, 4개인 GPU는 오른쪽 같이 실행 된다.
	- 물론 SM의 상태에 따라 블럭이 다이나믹하게 할당 됨.
		- H100의 경우 하나의 SM이 32개의 블럭을 처리 할 수 있다. 참고로 A40, A100은 각각 16개, 32개이다.

<p align="center">

<img width="350" alt="Pasted image 20240206121605" src="https://github.com/JinwoongKim/JinwoongKim.github.io/assets/12505517/b99bf320-6c54-4920-a730-338bc9a3d509">

<br>
출처 : https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html

</p>
# 4. GPU Trick or Tweak

- memory coalescing https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses
	- global memory 는 .. 무조건 256? align?
	- > Any address of a variable residing in global memory or returned by one of the memory allocation routines from the driver or runtime API is always aligned to at least 256 bytes.
	- soa, aos again
- unrolling
	- 많은 수의 코어가 놀지 않게 계속 데이터를 퍼주는게 GPU 병렬화의 핵심
	  - SIMT
		  - WARP (전우조)
			- 병렬화 최적화, 코어의 성능이 안 좋아서 최소 32개 묶음
				- 전우조라는 언급을 했듯이, if else 문이 있다고 했을때, 하나의 쓰레드라도 하나의 분기문에 해당되면 둘 다 들러야 함
				- 그래서, 분기문 안타게 코딩하는게 국룰
		- warp divergence
	- ILP
- Kernel fusion

# 5. 그 외
- 유니파이드 메모리
- 스트림
- 싱크로나이제이션
-  다이나믹 페러렐리즘
		- 커널 안에서 또 커널, 커널 런칭 오버헤드 감소
- 호환성
	- CPU 와의 호환성
	- GPU 와의 호환성
